{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/ubuntu/spark-2.1.1-bin-hadoop2.7\")\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"yye090_722\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load(\"./final1.csv\",format =\"csv\",header=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- WSPM: float (nullable = true)\n",
      " |-- station: string (nullable = true)\n",
      " |-- PM25: float (nullable = true)\n",
      " |-- SO2: float (nullable = true)\n",
      " |-- NO2: float (nullable = true)\n",
      " |-- CO: float (nullable = true)\n",
      " |-- O3: float (nullable = true)\n",
      " |-- TEMP: float (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- PM_Rating: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "changedTypedf = df.withColumn(\"year\", df[\"year\"].cast(\"integer\")).withColumn(\"month\", df[\"month\"].cast(\"integer\"))\\\n",
    ".withColumn(\"hour\", df[\"hour\"].cast(\"integer\"))\\\n",
    ".withColumn(\"day\", df[\"day\"].cast(\"integer\"))\\\n",
    ".withColumn(\"PM25\", df[\"PM25\"].cast(\"float\"))\\\n",
    ".withColumn(\"SO2\", df[\"SO2\"].cast(\"float\"))\\\n",
    ".withColumn(\"NO2\", df[\"NO2\"].cast(\"float\"))\\\n",
    ".withColumn(\"CO\", df[\"CO\"].cast(\"float\"))\\\n",
    ".withColumn(\"O3\", df[\"O3\"].cast(\"float\"))\\\n",
    ".withColumn(\"TEMP\", df[\"TEMP\"].cast(\"float\"))\\\n",
    ".withColumn(\"WSPM\", df[\"WSPM\"].cast(\"float\"))\n",
    "changedTypedf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+----+------------+----+----+----+-----+----+----+------+---------+------------+\n",
      "|year|month|day|hour|WSPM|     station|PM25| SO2| NO2|   CO|  O3|TEMP|Season|PM_Rating|stationIndex|\n",
      "+----+-----+---+----+----+------------+----+----+----+-----+----+----+------+---------+------------+\n",
      "|2013|    3|  1|   0| 5.7|Nongzhanguan| 5.0| 4.0|12.0|200.0|85.0|-0.5|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   1| 3.9|Nongzhanguan| 8.0| 6.0|14.0|200.0|84.0|-0.7|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   2| 5.3|Nongzhanguan| 3.0| 5.0|14.0|200.0|83.0|-1.2|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   3| 4.9|Nongzhanguan| 5.0| 5.0|14.0|200.0|84.0|-1.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   4| 3.2|Nongzhanguan| 5.0| 6.0|21.0|200.0|77.0|-1.9|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   5| 2.4|Nongzhanguan| 3.0|13.0|21.0|300.0|77.0|-2.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   6| 2.2|Nongzhanguan| 4.0|15.0|32.0|300.0|62.0|-2.5|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   7| 3.0|Nongzhanguan| 3.0|14.0|45.0|400.0|48.0|-1.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   8| 4.6|Nongzhanguan| 3.0|13.0|49.0|400.0|46.0|-0.3|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|   9| 5.5|Nongzhanguan|11.0| 9.0|28.0|400.0|68.0| 0.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  10| 5.2|Nongzhanguan| 3.0| 6.0|20.0|300.0|77.0| 1.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  11| 5.3|Nongzhanguan| 3.0| 6.0|19.0|300.0|81.0| 2.9|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  12| 4.6|Nongzhanguan| 3.0| 4.0|17.0|300.0|86.0| 4.0|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  13| 4.5|Nongzhanguan| 3.0| 4.0|17.0|300.0|87.0| 5.0|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  14| 4.0|Nongzhanguan| 6.0| 4.0|19.0|300.0|86.0| 6.2|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  15| 2.1|Nongzhanguan| 5.0| 4.0|18.0|300.0|89.0| 6.0|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  16| 1.8|Nongzhanguan| 5.0| 4.0|21.0|300.0|85.0| 5.6|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  17| 3.5|Nongzhanguan|10.0| 8.0|25.0|400.0|80.0| 4.4|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  18| 0.5|Nongzhanguan|11.0| 7.0|27.0|400.0|77.0| 3.2|Spring|Excellent|         7.0|\n",
      "|2013|    3|  1|  19| 1.1|Nongzhanguan|11.0|12.0|39.0|400.0|64.0| 3.0|Spring|Excellent|         7.0|\n",
      "+----+-----+---+----+----+------------+----+----+----+-----+----+----+------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer, VectorAssembler, StandardScaler, StringIndexer\n",
    "cat_column = [\"station\"]\n",
    "for i in cat_column:\n",
    "    indexer = StringIndexer(inputCol=i, outputCol=i + \"Index\")\n",
    "    model = indexer.fit(df)\n",
    "    new = model.transform(df)\n",
    "    df = new\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- WSPM: float (nullable = true)\n",
      " |-- PM25: float (nullable = true)\n",
      " |-- SO2: float (nullable = true)\n",
      " |-- NO2: float (nullable = true)\n",
      " |-- CO: float (nullable = true)\n",
      " |-- O3: float (nullable = true)\n",
      " |-- TEMP: float (nullable = true)\n",
      " |-- stationIndex: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import *\n",
    "new_df = df.drop(*[\"station\",\"Season\",\"PM_Rating\"])\n",
    "new_df = new_df.withColumn(\"year\", new_df[\"year\"].cast(\"integer\")).withColumn(\"month\", new_df[\"month\"].cast(\"integer\"))\\\n",
    ".withColumn(\"hour\", new_df[\"hour\"].cast(\"integer\"))\\\n",
    ".withColumn(\"day\", new_df[\"day\"].cast(\"integer\"))\\\n",
    ".withColumn(\"PM25\", new_df[\"PM25\"].cast(\"float\"))\\\n",
    ".withColumn(\"SO2\", new_df[\"SO2\"].cast(\"float\"))\\\n",
    ".withColumn(\"NO2\", new_df[\"NO2\"].cast(\"float\"))\\\n",
    ".withColumn(\"CO\", new_df[\"CO\"].cast(\"float\"))\\\n",
    ".withColumn(\"O3\", new_df[\"O3\"].cast(\"float\"))\\\n",
    ".withColumn(\"TEMP\", new_df[\"TEMP\"].cast(\"float\"))\\\n",
    ".withColumn(\"WSPM\", new_df[\"WSPM\"].cast(\"float\"))\n",
    "new_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+---+----+----+----+----+----+-----+----+----+------------+\n",
      "|year|month|day|hour|WSPM|PM25| SO2| NO2|   CO|  O3|TEMP|stationIndex|\n",
      "+----+-----+---+----+----+----+----+----+-----+----+----+------------+\n",
      "|2013|    3|  1|   0| 3.1| 7.0| 3.0| 2.0|100.0|91.0|-2.3|         1.0|\n",
      "|2013|    3|  1|   5| 4.3| 4.0| 3.0| 3.0|200.0|85.0|-4.2|         1.0|\n",
      "|2013|    3|  1|   6| 0.6| 3.0|33.0| 7.0|300.0|82.0|-5.9|         1.0|\n",
      "|2013|    3|  1|   7| 3.4| 3.0|13.0|13.0|400.0|71.0|-2.7|         1.0|\n",
      "|2013|    3|  1|   8| 4.6| 3.0|34.0|38.0|800.0|45.0|-1.6|         1.0|\n",
      "|2013|    3|  1|  10| 2.7|19.0| 5.0| 3.0|300.0|85.0| 1.0|         1.0|\n",
      "|2013|    3|  1|  12| 1.9| 3.0| 5.0| 3.0|300.0|86.0| 3.9|         1.0|\n",
      "|2013|    3|  1|  13| 3.3| 3.0| 7.0| 3.0|300.0|87.0| 4.7|         1.0|\n",
      "|2013|    3|  1|  14| 1.9| 3.0| 9.0| 6.0|300.0|87.0| 5.7|         1.0|\n",
      "|2013|    3|  1|  15| 3.1| 3.0| 4.0| 3.0|200.0|89.0| 5.4|         1.0|\n",
      "|2013|    3|  1|  16| 3.2| 3.0|16.0| 6.0|300.0|86.0| 4.6|         1.0|\n",
      "|2013|    3|  1|  17| 2.8| 4.0|13.0|12.0|300.0|80.0| 3.4|         1.0|\n",
      "|2013|    3|  1|  18| 1.4| 4.0|10.0|15.0|300.0|76.0| 1.2|         1.0|\n",
      "|2013|    3|  1|  19| 2.3| 9.0|24.0|22.0|500.0|68.0| 0.8|         1.0|\n",
      "|2013|    3|  1|  20| 4.4|20.0|22.0|24.0|500.0|65.0| 0.7|         1.0|\n",
      "|2013|    3|  1|  21| 3.3|23.0|27.0|16.0|400.0|71.0|-0.2|         1.0|\n",
      "|2013|    3|  1|  22| 3.7|13.0|23.0|18.0|400.0|68.0|-1.0|         1.0|\n",
      "|2013|    3|  2|   0| 4.8|15.0|44.0|28.0|500.0|57.0|-1.8|         1.0|\n",
      "|2013|    3|  2|   1| 2.6| 9.0|28.0|17.0|400.0|67.0|-2.1|         1.0|\n",
      "|2013|    3|  2|   2| 3.9|11.0|40.0|16.0|300.0|67.0|-2.2|         1.0|\n",
      "+----+-----+---+----+----+----+----+----+-----+----+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|            features|PM25|\n",
      "+--------------------+----+\n",
      "|[2013.0,3.0,1.0,0...| 5.0|\n",
      "|[2013.0,3.0,1.0,1...| 8.0|\n",
      "|[2013.0,3.0,1.0,2...| 3.0|\n",
      "|[2013.0,3.0,1.0,3...| 5.0|\n",
      "|[2013.0,3.0,1.0,4...| 5.0|\n",
      "|[2013.0,3.0,1.0,5...| 3.0|\n",
      "|[2013.0,3.0,1.0,6...| 4.0|\n",
      "|[2013.0,3.0,1.0,7...| 3.0|\n",
      "|[2013.0,3.0,1.0,8...| 3.0|\n",
      "|[2013.0,3.0,1.0,9...|11.0|\n",
      "|[2013.0,3.0,1.0,1...| 3.0|\n",
      "|[2013.0,3.0,1.0,1...| 3.0|\n",
      "|[2013.0,3.0,1.0,1...| 3.0|\n",
      "|[2013.0,3.0,1.0,1...| 3.0|\n",
      "|[2013.0,3.0,1.0,1...| 6.0|\n",
      "|[2013.0,3.0,1.0,1...| 5.0|\n",
      "|[2013.0,3.0,1.0,1...| 5.0|\n",
      "|[2013.0,3.0,1.0,1...|10.0|\n",
      "|[2013.0,3.0,1.0,1...|11.0|\n",
      "|[2013.0,3.0,1.0,1...|11.0|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "f = RFormula(formula=\"PM25~.\",featuresCol=\"features\",labelCol=\"PM25\")\n",
    "output = f.fit(new_df).transform(new_df)\n",
    "feature_selection = output.select(\"features\",\"PM25\")\n",
    "feature_selection.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = feature_selection.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|             PM25|\n",
      "+-------+-----------------+\n",
      "|  count|           150376|\n",
      "|   mean|58.92798917380243|\n",
      "| stddev|51.61688005442644|\n",
      "|    min|              2.0|\n",
      "|    max|            247.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+-----------------+\n",
      "|summary|             PM25|\n",
      "+-------+-----------------+\n",
      "|  count|            64604|\n",
      "|   mean|59.27802767612478|\n",
      "| stddev|51.98201006861113|\n",
      "|    min|              2.0|\n",
      "|    max|            247.0|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see our training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(labelCol='PM25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 1278.7466147101736\n",
      "year:  -0.6437035586144365\n",
      "month:  -0.9705032941522183\n",
      "day:  0.10276732030771647\n",
      "hour:  -0.4373188321503156\n",
      "WSPM:  0.10294537842719416\n",
      "SO2:  0.03861075390764678\n",
      "NO2:  0.3935322244396976\n",
      "CO:  0.05925330203979991\n",
      "O3:  0.20371076241833677\n",
      "TEMP:  0.6031295884097563\n",
      "stationIndex:  -0.9469968092326163\n"
     ]
    }
   ],
   "source": [
    "coefficients = lrModel.coefficients\n",
    "cof_col = new_df.drop(*[\"PM25\"]).columns\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "for i in range(len(cof_col)):\n",
    "    print(cof_col[i] + \":  \" +str(coefficients[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = lrModel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "|  0.836108922381527|\n",
      "| 3.4865492186941083|\n",
      "| -7.321259995236687|\n",
      "| -4.689992952402463|\n",
      "|-2.8617597581560403|\n",
      "| -2.845554250407531|\n",
      "| -8.671291073205111|\n",
      "|0.22091144192586398|\n",
      "| -5.266151365391124|\n",
      "|-1.3458786532376052|\n",
      "|-10.704280294052523|\n",
      "| -3.518874871732578|\n",
      "| -9.589942153592801|\n",
      "|-13.890154742294271|\n",
      "| 0.9292897047059796|\n",
      "|  8.380239325617367|\n",
      "| -7.156836729158613|\n",
      "|  -8.26196851574582|\n",
      "| -9.374430512309573|\n",
      "| -8.604155035677422|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RSME: 32.48611848123089\n"
     ]
    }
   ],
   "source": [
    "# Interesting results! This shows the difference between the predicted value and the test data.\n",
    "test_results.residuals.show()\n",
    "# Let's get some evaluation metrics (as discussed in the previous linear regression notebook).\n",
    "print(\"RSME: {}\".format(test_results.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RootMeanSquaredError: 32.48611848123089\n",
      "MeanSquaredError: 1055.347893976571\n",
      "R2: 0.6094323827394463\n"
     ]
    }
   ],
   "source": [
    "print(\"RootMeanSquaredError: \" + str(test_results.rootMeanSquaredError))\n",
    "print(\"MeanSquaredError: \" + str(test_results.meanSquaredError))\n",
    "print(\"R2: \" + str(test_results.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|PM25|        prediction|\n",
      "+----+------------------+\n",
      "| 9.0| 8.163891077618473|\n",
      "| 7.0|3.5134507813058917|\n",
      "| 8.0|15.321259995236687|\n",
      "| 9.0|13.689992952402463|\n",
      "| 5.0|  7.86175975815604|\n",
      "| 3.0| 5.845554250407531|\n",
      "| 6.0|14.671291073205111|\n",
      "| 8.0| 7.779088558074136|\n",
      "| 9.0|14.266151365391124|\n",
      "| 5.0| 6.345878653237605|\n",
      "| 3.0|13.704280294052523|\n",
      "| 3.0| 6.518874871732578|\n",
      "| 3.0|12.589942153592801|\n",
      "| 5.0| 18.89015474229427|\n",
      "| 6.0|  5.07071029529402|\n",
      "|10.0|1.6197606743826327|\n",
      "| 4.0|11.156836729158613|\n",
      "|10.0| 18.26196851574582|\n",
      "| 3.0|12.374430512309573|\n",
      "| 3.0|11.604155035677422|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Now we can transform the unlabeled data.\n",
    "predictions = lrModel.transform(test_data)\n",
    "predictions.select(\"PM25\",\"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = predictions.select(\"PM25\",\"prediction\").toPandas()\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x[\"PM25\"])\n",
    "plt.plot(x[\"prediction\"])\n",
    "plt.xlabel(\"PM2.5\")\n",
    "plt.ylabel(\"ID\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
